import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import os
import itertools

class GradientReversalFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha
        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        return grad_output.neg() * ctx.alpha, None

class GradientReversalLayer(nn.Module):
    def forward(self, x, alpha=1.0):
        return GradientReversalFunction.apply(x, alpha)

class FeatureExtractor(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(14, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU()
        )

    def forward(self, x):
        return self.network(x)

class LabelPredictor(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )

    def forward(self, x):
        return self.network(x)

class DomainClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 2)
        )

    def forward(self, x):
        return self.network(x)

def kge(y_true, y_pred):
    r = np.corrcoef(y_true, y_pred)[0, 1]
    beta = np.mean(y_pred) / np.mean(y_true)
    gamma = (np.std(y_pred)/np.mean(y_pred)) / (np.std(y_true)/np.mean(y_true))
    return 1 - np.sqrt((r-1)**2 + (beta-1)**2 + (gamma-1)**2)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

data = pd.read_csv('D:/train_data.csv') 
features = ['TA', 'TArange', 'VPD', 'WS', 'SSM', 'RSDN', 'LAI']

target = 'ET'
site_ids = data['SITE_ID'].unique()

results_path = 'D:/results.csv'

def adjust_lambda(progress):
    if progress < 0.2:
        return 0.0
    else:
        adjusted_progress = (progress - 0.2) / 0.8
        return 2 / (1 + np.exp(-10 * adjusted_progress)) - 1

def train_model_with_warmup_and_weight(test_site_id):
    train_data = data[data['SITE_ID'] != test_site_id]
    test_data = data[data['SITE_ID'] == test_site_id]

    X_train = train_data[features].values
    y_train = train_data[target].values.reshape(-1, 1)
    X_test = test_data[features].values
    y_test = test_data[target].values.reshape(-1, 1)

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    n_source = X_train.shape[0]
    n_target = X_test.shape[0]
    source_weight = 1.0 / (2 * n_source)  
    target_weight = 1.0 / (2 * n_target)

    X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)
    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)
    X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)
    y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)

    source_loader = DataLoader(TensorDataset(X_train_t, y_train_t), 
                             batch_size=64, shuffle=True)
    target_loader = itertools.cycle(DataLoader(TensorDataset(X_test_t), 
                                   batch_size=64, shuffle=True))

    feature_extractor = FeatureExtractor().to(device)
    label_predictor = LabelPredictor().to(device)
    domain_classifier = DomainClassifier().to(device)
    grl = GradientReversalLayer()

    optimizer = optim.Adam(list(feature_extractor.parameters()) +
                         list(label_predictor.parameters()) +
                         list(domain_classifier.parameters()), lr=0.001)
    criterion_reg = nn.MSELoss()
    criterion_domain = nn.CrossEntropyLoss(reduction='none') 

    num_epochs = 50
    for epoch in range(num_epochs):
        feature_extractor.train()
        total_loss = 0.0
        progress = epoch / num_epochs
        lambda_val = adjust_lambda(progress) 

        for src_X, src_y in source_loader:
            tgt_X = next(target_loader)[0].to(device)

            src_feat = feature_extractor(src_X)
            tgt_feat = feature_extractor(tgt_X)

            pred = label_predictor(src_feat)
            loss_reg = criterion_reg(pred, src_y)

            combined_feat = torch.cat([src_feat, tgt_feat])
            domain_input = grl(combined_feat, alpha=lambda_val)
            domain_pred = domain_classifier(domain_input)

            batch_source = src_X.size(0)
            batch_target = tgt_X.size(0)
            weights = torch.cat([
                torch.full((batch_source,), source_weight, device=device),
                torch.full((batch_target,), target_weight, device=device)
            ])

            domain_labels = torch.cat([
                torch.zeros(batch_source, dtype=torch.long),
                torch.ones(batch_target, dtype=torch.long)
            ]).to(device)
            
            loss_domain = (criterion_domain(domain_pred, domain_labels) * weights).mean()
            loss = loss_reg + lambda_val * loss_domain

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()

        print(f'Epoch [{epoch+1:02d}/{num_epochs}] Loss: {total_loss/len(source_loader):.4f} '
              f'Lambda: {lambda_val:.2f}')

    feature_extractor.eval()
    with torch.no_grad():
        test_feat = feature_extractor(X_test_t)
        y_pred = label_predictor(test_feat).squeeze().cpu().numpy()
        y_true = y_test_t.squeeze().cpu().numpy()
        return kge(y_true, y_pred)

results = []
for site_index, test_site_id in enumerate(site_ids):
    print(f'\nProcessing site {site_index+1}/{len(site_ids)}: {test_site_id}')
    kge_score = train_model_with_warmup_and_weight(test_site_id)
    results.append({'SITE_ID': test_site_id, 'KGE': kge_score})

pd.DataFrame(results).to_csv(results_path, index=False)
print(f'Results saved to {results_path}')
