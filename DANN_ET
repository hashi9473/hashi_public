import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import os
import itertools


class GradientReversalFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha
        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        return grad_output.neg() * ctx.alpha, None

class GradientReversalLayer(nn.Module):
    def __init__(self):
        super().__init__()
    
    def forward(self, x, alpha=1.0):
        return GradientReversalFunction.apply(x, alpha)


class FeatureExtractor(nn.Module):
    def __init__(self):
        super(FeatureExtractor, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(14, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU()
        )

    def forward(self, x):
        return self.network(x)

class LabelPredictor(nn.Module):
    def __init__(self):
        super(LabelPredictor, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )

    def forward(self, x):
        return self.network(x)

class DomainClassifier(nn.Module):
    def __init__(self):
        super(DomainClassifier, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 2)
        )

    def forward(self, x):
        return self.network(x)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
feature_extractor = FeatureExtractor().to(device)
label_predictor = LabelPredictor().to(device)
domain_classifier = DomainClassifier().to(device)
optimizer = optim.Adam(list(feature_extractor.parameters()) +
                     list(label_predictor.parameters()) +
                     list(domain_classifier.parameters()), lr=0.001)

def kge(y_true, y_pred):
    r = np.corrcoef(y_true, y_pred)[0, 1]
    beta = np.mean(y_pred) / np.mean(y_true)
    gamma = (np.std(y_pred)/np.mean(y_pred)) / (np.std(y_true)/np.mean(y_true))
    return 1 - np.sqrt((r-1)**2 + (beta-1)**2 + (gamma-1)**2)


data = dk  
features = ['TA', 'TArange', 'VPD', 'WS', 'SSM', 'RSDN', 'LAI',
            'GSmax', 'G1', 'GPPsat', 'MAT', 'MAP', 'Hc', 'sand_frac']
target = 'ET'
site_ids = data['SITE_ID'].unique()


def adjust_lambda(progress):
    return 2 / (1 + np.exp(-10 * progress)) - 1

results = []
grl = GradientReversalLayer()

for site_index, test_site_id in enumerate(site_ids):
    print(f'\nProcessing site {site_index+1}/{len(site_ids)}: {test_site_id}')
    
    train_data = data[data['SITE_ID'] != test_site_id]
    test_data = data[data['SITE_ID'] == test_site_id]

    X_train = train_data[features].values
    y_train = train_data[target].values.reshape(-1, 1)
    X_test = test_data[features].values
    y_test = test_data[target].values.reshape(-1, 1)

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)
    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)
    X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)
    y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)

    source_loader = DataLoader(TensorDataset(X_train_t, y_train_t), 
                             batch_size=64, shuffle=True, num_workers=4)
    target_loader = itertools.cycle(DataLoader(TensorDataset(X_test_t), 
                                   batch_size=64, shuffle=True, num_workers=4))

    num_epochs = 50
    for epoch in range(num_epochs):
        feature_extractor.train()
        label_predictor.train()
        domain_classifier.train()

        total_loss = 0.0
        progress = epoch / num_epochs
        lambda_val = adjust_lambda(progress)

        for src_X, src_y in source_loader:
            tgt_X = next(target_loader)[0].to(device)

            src_feat = feature_extractor(src_X)
            tgt_feat = feature_extractor(tgt_X)
            pred = label_predictor(src_feat)
            
            loss_reg = nn.MSELoss()(pred, src_y)
            
            combined_feat = torch.cat([src_feat, tgt_feat])
            if lambda_val > 0:
                domain_input = grl(combined_feat, alpha=lambda_val)
            else:
                domain_input = combined_feat
                
            domain_pred = domain_classifier(domain_input)
            domain_labels = torch.cat([
                torch.zeros(src_X.size(0)), 
                torch.ones(tgt_X.size(0))
            ]).long().to(device)
            loss_domain = nn.CrossEntropyLoss()(domain_pred, domain_labels)
            
            loss = loss_reg + lambda_val * loss_domain

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()

        print(f'Epoch [{epoch+1:02d}/{num_epochs}] Loss: {total_loss/len(source_loader):.4f}')

    feature_extractor.eval()
    label_predictor.eval()
    with torch.no_grad():
        test_feat = feature_extractor(X_test_t)
        y_pred = label_predictor(test_feat).squeeze().cpu().numpy()
        y_true = y_test_t.squeeze().cpu().numpy()
        kge_score = kge(y_true, y_pred)
        results.append({'SITE_ID': test_site_id, 'KGE_leak': kge_score})

results_df = pd.DataFrame(results)
results_path = 'D:/results.csv'
results_df.to_csv(results_path, index=False)
